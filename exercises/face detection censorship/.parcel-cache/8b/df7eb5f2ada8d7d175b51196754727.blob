const video = document.querySelector('.webcam');
const canvas = document.querySelector('.video');
const ctx = canvas.getContext('2d');
const faceCanvas = document.querySelector('.face');
const faceCtx = faceCanvas.getContext('2d');
const faceDetector = new window.FaceDetector(); // console.log(video, canvas, faceCanvas, faceDetector);
// function to populate user video

async function populateVideo() {
  const stream = await navigator.mediaDevices.getUserMedia({
    video: {
      width: 1280,
      height: 720
    }
  });
  video.srcObject = stream;
  await video.play(); // size canvas to be same size as video

  console.log(video.videoWidth, video.videoHeight);
  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;
  faceCanvas.width = video.videoWidth;
  faceCanvas.height = video.videoHeight;
}

async function detect() {
  const faces = await faceDetector.detect(video); // ask browser when next animation frame is, and have it run detect for us

  faces.forEach(drawFace);
  requestAnimationFrame(detect); // console.log(faces);
}

function drawFace(face) {
  const {
    width,
    height,
    top,
    left
  } = face.boundingBox;
  ctx.strokeRect(left, top, width, height);
  ctx.clearRect(0, 0, canvas.wi);
  ctx.strokeStyle = '#030ffc';
  ctx.lineWidth = 2; // console.log({width,height,top,left});
}

populateVideo().then(detect);